## 1. ì–¸ì–´ ëª¨ë¸

- ì–¸ì–´ ëª¨ë¸
    - ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ **í™•ë¥ **ì„ ê³„ì‚°í•˜ëŠ” ëª¨ë¸
    - ë‹¨ì–´ ì‹œí€€ìŠ¤ì˜ í™•ë¥  P(W) : P(w1, w2, w3, â€¦, wn)
    - ì´ì „ ë‹¨ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ê°€ ë‚˜ì˜¬ í™•ë¥  : P(wn | w1, w2, w3, â€¦, wn-1)

- í™•ë¥ ì˜ ê³„ì‚°
    
    ![2024-10-18_17-21-36.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/5eb360a9-16f8-44d3-8788-cf780ee1902d/2024-10-18_17-21-36.jpg)
    
    â†’ 0 ë˜ëŠ” 0/0ì´ ë  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
    
    â‡’ ì—°ì‡„ ê·œì¹™(Chain rule) & ë…ë¦½ ê°€ì •ì„ ì‚¬ìš©í•´ì•¼ í•¨!
    

### (1) ë² ì´ì¦ˆ ì •ë¦¬

- ì¡°ê±´ë¶€í™•ë¥ 
    
    $P(A|B) = \frac{P(A, B)}{P(B)}$
    
    - P(A, B): Aì™€ Bê°€ ë™ì‹œì— ë°œìƒí•  í™•ë¥  (ê²°í•© í™•ë¥ )
        
        â†’ $P(A, B) = P(A|B)P(B)$
        

- ë² ì´ì¦ˆ ì •ë¦¬
    - **ì¡°ê±´ë¶€ í™•ë¥ **ì„ ì‚¬ìš©í•˜ì—¬ **ì‚¬ì „ í™•ë¥ **ì„ **ì‚¬í›„ í™•ë¥ **ë¡œ ê°±ì‹ í•˜ëŠ” ë°©ë²•
    - **ìƒˆë¡œìš´ ì •ë³´**ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ê¸°ì¡´ ì§€ì‹ì„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
    - ì‚¬ê±´ Aê°€ ë°œìƒí–ˆì„ ë•Œ ì‚¬ê±´ Bê°€ ë°œìƒí•  í™•ë¥ 
    - ê³µì‹:
        
        $P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$
        
        - P(A|B): Bê°€ ì£¼ì–´ì¡Œì„ ë•Œ Aê°€ ì¼ì–´ë‚  í™•ë¥  (ì‚¬í›„ í™•ë¥ , Posterior Probability)
        - P(B|A): Aê°€ ì£¼ì–´ì¡Œì„ ë•Œ Bê°€ ì¼ì–´ë‚  í™•ë¥  (ìš°ë„, Likelihood)
        - P(A): Aê°€ ì¼ì–´ë‚  í™•ë¥  (ì‚¬ì „ í™•ë¥ , Prior Probability)
        - P(B): Bê°€ ì¼ì–´ë‚  í™•ë¥  (ì •ê·œí™” ìƒìˆ˜)

- ì—°ì‡„ ê·œì¹™ (Chain Rule)
    - P(x1,x2,x3,â€¦xn) = P(x1)P(x2|x1)P(x3|x1,x2)â€¦P(xn|x1â€¦xn-1)
    - ex.
        
        P(ë‚˜ëŠ”, ì–´ì œ, ì¹œêµ¬ì™€, ì˜í™”ë¥¼, ë´¤ë‹¤)
        = P(ë‚˜ëŠ”)
        * P(ì–´ì œ | ë‚˜ëŠ”)
        * P(ì¹œêµ¬ì™€ | ë‚˜ëŠ”, ì–´ì œ)
        * P(ì˜í™”ë¥¼ | ë‚˜ëŠ”, ì–´ì œ, ì¹œêµ¬ì™€)
        * P(ë´¤ë‹¤ | ë‚˜ëŠ”, ì–´ì œ, ì¹œêµ¬ì™€, ì˜í™”ë¥¼)
        

### (2) N-gram ëª¨ë¸

- ë§ˆë¥´ì½”í”„ ê°€ì •
    - ì£¼ì–´ì§„ í˜„ì¬ ìƒíƒœê°€ **ë¯¸ë˜ ìƒíƒœ**ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²°ì •í•˜ëŠ” ë° ìˆì–´ì„œ **ê³¼ê±° ìƒíƒœì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê°€ì •**
    - **í˜„ì¬ ìƒíƒœ**ë§Œìœ¼ë¡œ **ë¯¸ë˜ ìƒíƒœ**ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆê³ , **ê³¼ê±°ì˜ ì •ë³´ëŠ” ë¬´ì‹œí•  ìˆ˜ ìˆë‹¤**ëŠ” ê°€ì •

- ì¡°ê±´ë¶€ ë…ë¦½
    - ë‘ ì‚¬ê±´ **A**ì™€ **B**ê°€ **ë‹¤ë¥¸ ì‚¬ê±´ C**ê°€ ì£¼ì–´ì§„ ìƒíƒœì—ì„œ **ì„œë¡œ ë…ë¦½ì **
    - $P(A \cap B | C) = P(A | C) \cdot P(B | C)$

- N-gram ëª¨ë¸
    - ì´ì „ N-1ê°œì˜ ë‹¨ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì— ë‚˜ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í™•ë¥  ëª¨ë¸
    - N-gram = ê¸¸ì´ê°€ Nì¸ í† í°ì˜ ì—´
    
    - Bigram(2-gram) ëª¨ë¸
        - ë‘ ê°œì˜ ì—°ì†ëœ ë‹¨ì–´ë¥¼ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡
        - $ğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{1,ğ‘›âˆ’1})â‰ˆğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{ğ‘›âˆ’1})$
        - $P(w_{1,n}) \approx \prod_{i=1}^{n} P(w_i | w_{i-1})$
            - ì „ì²´ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ë“¤ì´ ë‚˜ì˜¬ í™•ë¥  = ì´ì „ ë‹¨ì–´ê°€ ë‚˜ì™”ì„ ë•Œ í˜„ì¬ ë‹¨ì–´ê°€ ë‚˜ì˜¬ í™•ë¥ ì˜ ê³±
        - ex. P(â€œë´¤ë‹¤â€ | â€œì˜í™”ë¥¼â€)
        
    - Trigram(3-gram) ëª¨ë¸
        - ì„¸ ê°œì˜ ì—°ì†ëœ ë‹¨ì–´ë¥¼ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡
        - $ğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{1,ğ‘›âˆ’1})â‰ˆğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{ğ‘›âˆ’2,ğ‘›âˆ’1})$
        - $P(w_{1,n}) \approx \prod_{i=1}^{n} P(w_i | w_{i-2,i-1})$
            - ì „ì²´ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ë“¤ì´ ë‚˜ì˜¬ í™•ë¥  = ì´ì „ ë‘ ë‹¨ì–´ê°€ ë‚˜ì™”ì„ ë•Œ í˜„ì¬ ë‹¨ì–´ê°€ ë‚˜ì˜¬ í™•ë¥ ì˜ ê³±
        - ex. Â P(â€œë´¤ë‹¤â€ | â€œì¹œêµ¬ì™€â€, â€œì˜í™”ë¥¼â€)

- ìµœìš°ì¶”ì • (MLE)
    - N-gram ëª¨ë¸ì—ì„œ ë‹¨ì–´ì˜ í™•ë¥ ì„ ì¶”ì •í•˜ëŠ” ë°©ì‹
    1. Bigram
        - $P(w_i | w_{i-1}) = \frac{\text{freq}(w_{i-1}, w_i)}{\text{freq}(w_{i-1})}$
            - ì´ì „ ë‹¨ì–´ $w_{i-1}$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ **ë‹¤ìŒ ë‹¨ì–´ $w_i$**ê°€ ë‚˜ì˜¬ í™•ë¥ 
            - $w_{i-1}, w_{i}$ì´ í•¨ê»˜ ë‚˜íƒ€ë‚œ ë¹ˆë„ / $w_{i-1}$ê°€ ë‚˜íƒ€ë‚œ ë¹ˆë„
    2. Trigram
        - $P(w_i | w_{i-2}, w_{i-1}) = \frac{\text{freq}(w_{i-2}, w_{i-1}, w_i)}{\text{freq}(w_{i-2}, w_{i-1})}$

## 2. Bigram ì–¸ì–´ ëª¨ë¸ í™œìš© ê³¼ì •

> Berkeley Restaurant Project ì˜ˆì‹œ ë¬¸ì¥ 9222ê°œ
> 
> - *can you tell me about any good cantonese restaurants close by*
> - *mid priced thai food is what iâ€™m looking for*
> - *tell me about chez panisse*
> - *can you give me a listing of the kinds of food that are available*
> - *iâ€™m looking for a good place to eat breakfast*
> - *when is caffe venezia open during the day*

1. Raw Bigram Count (2-gram ë¹ˆë„ìˆ˜ ì¸¡ì •)
    
    ![2024-10-18_21-09-20.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/a922c639-9b45-4ce5-a36e-b853a40224d6/2024-10-18_21-09-20.jpg)
    
    - ex. â€œI wantâ€ : 827ë²ˆ ë“±ì¥

1. Raw Bigram Probabilities (2-gram í™•ë¥  ê³„ì‚°)
    
    ![2024-10-18_21-10-40.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/f9ec968d-b5ea-4e13-aa69-14edcf42e366/2024-10-18_21-10-40.jpg)
    
    - ex. P(want | I) = freq(I, want) / freq(I) = 827 / 2533 = 0.33

1. ë¬¸ì¥ í™•ë¥  ì¶”ì •
    
    ![2024-10-18_21-11-51.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/e29928f1-9a48-43fc-aeff-a944f438a0b3/2024-10-18_21-11-51.jpg)
    
    ë¬¸ì¥ ì „ì²´ì˜ í™•ë¥ ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ ê° ë‹¨ì–´ ìŒì˜ Bigram í™•ë¥ ì„ ê³±í•¨
    

1. ì–¸ì–´ì  ì§€ì‹ í¬ì°©
    1. World Knowledge
        - íŠ¹ì • ë‹¨ì–´ë“¤ì´ í•¨ê»˜ ë“±ì¥í•  ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ„
        - ex. want ë‹¤ìŒì—ëŠ” englishë³´ë‹¤ toê°€ ë‚˜ì˜¬ í™•ë¥ ì´ ë†’ìŒ
            - P(to|want) = .66
            - P(english|want) = .0011
    2. Syntax
        - ë¬¸ë²•ì  ì§€ì‹ ë°˜ì˜
            - P(want | spend) = 0
            - P(food | to) = 0

## 3. Shannonâ€™s Method

- Shannonâ€™s Method
    - í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ì„ì˜ì˜ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ë°©ë²•
    - N-gram ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í™•ë¥ ì ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ê³  ë¬¸ì¥ì„ ìƒì„±
    - ê³¼ì •:
        1. ì²«ë‹¨ì–´ : <s>(ë¬¸ì¥ì˜ ì‹œì‘) ì´í›„ì— ë‚˜ì˜¬ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ë‹¨ì–´ë¡œ **Bigram** í™•ë¥ ì„ ì´ìš©í•˜ì—¬ ì„ íƒ
        2. **ë‘ ë²ˆì§¸ ë‹¨ì–´**ëŠ” **ì´ì „ ë‹¨ì–´**ê°€ ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‹¨ì–´ë¥¼ ì„ íƒ
        3. </s> ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µ
            
            ![2024-10-18_21-40-27.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/441f3624-d939-4980-b8ca-ad2bde031628/2024-10-18_21-40-27.jpg)
            

- ì…°ìµìŠ¤í”¼ì–´ ë¬¸ì²´ ìƒì„±
    1. Unigram : *To him swallowed confess hear both.*
    2. Bigram : *What means, sir. I confess she then all sorts, he is trim, captain.*
    3. Trigram : *Sweet prince, Falstaff shall die. Harry of Monmouthâ€™s grave.*
    4. Quadrtigram : *King Henry: What! I will go seek the traitor Gloucester.*
    
    â†’ N-gramì˜ ê¸¸ì´ì— ë”°ë¼ ìƒì„±ë˜ëŠ” ë¬¸ì¥ì´ ì ì  ë” ìì—°ìŠ¤ëŸ½ê³  ì˜ë¯¸ ìˆê²Œ ë³€í™”
    
- ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ì €ë„ ë¬¸ì²´ ìƒì„±
    1. Unigram : *Months the my and issue of year foreign new exchangeâ€™s* 
    2. Bigram : *Last December through the way to preserve the Hudson corporation*
    3. Trigram : *They also point to ninety nine point six billion dollars from two hundred four*
    
    â†’ 
    
    - ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ì €ë„ì˜ ë¬¸ì²´ê°€ ì…°ìµìŠ¤í”¼ì–´ì™€ëŠ” ë§¤ìš° ë‹¤ë¦„
    - N-gram ëª¨ë¸ì´ ë¬¸ì²´ë¥¼ ë¶„ì„í•˜ê³  ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°©ë²•ì„ ì„¤ëª…
