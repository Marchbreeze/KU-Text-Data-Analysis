## 1. 텍스트 분류

- 텍스트 분류 (Text Classification)
    - 주어진 텍스트 데이터를 기반으로, 해당 텍스트를 **특정 클래스나 카테고리로 분류하는 작업**
    - 다양한 응용 분야에서 활용됨
        - 주제 분류, 스팸 탐지, 저자 식별, 연령 성별 식별, 장르 감지, 언어 감지, 감정 분석

- 텍스트 분류의 기본 요소
    1. Input
        - 문서 d: 분류할 텍스트 데이터 (문서, 이메일, 리뷰 등)
        - 고정된 클래스 집합 C: 분류할 수 있는 카테고리 또는 클래스의 집합 (스팸-정상, 주제 분류 …)
    2. Output
        - 예측된 클래스 c: 문서 d가 어떤 카테고리에 속하는지 예측된 클래스

- 텍스트 분류 기법
    1. Hand-coded Rules
        - 수작업으로 규칙을 코딩
        - 단어 또는 특징의 조합을 기반으로 규칙 작성
            - ex. black-list-address OR (“dollars” AND “have been selected” 포함) → 스팸 처리
        - 전문가가 규칙을 정교하게 작성하면 높은 정확도 기대 가능
        - 비용이 큼
        
    2. Supervised Machine Learning
        - 지도학습 활용
        - Input에 훈련 데이터 세트 (m개의 라벨이 지정된 문서로 구성) 포함
            - 문서와 라벨의 쌍 - (d₁, c₁), (d₂, c₂), …, (d_m, c_m)
        - Output
            - 학습된 분류기 : 문서 d를 받아들여 예측된 클래스 c를 출력 (γ : d → c)
        - 라벨이 지정된 훈련 데이터 구축에 시간 소요
        - 비전문가에 의해 데이터 구축 및 개선 가능

- ****지도 학습을 위한 분류기 (Classifier) 종류
    - Naïve Bayes
    - Logistic regression
    - Support-vector machines(SVM)
    - k-Nearest Neighbors(k-NN)

## 2. **Naïve Bayes**

### **(1) Naïve Bayes Classifier**

- Naïve Bayes 분류기
    - **베이즈 정리**를 기반으로 한 매우 단순한 분류 방법
    - Naive : 모든 특성(여기서는 단어)이 **서로 독립적**이라고 가정
    - 단순한 문서 표현 방식 사용 - Bag of Words(BOW)

- Bag of Words(BOW)
    - 문서를 단어들의 모음으로 표현하고, 각 단어가 문서 내에서 몇 번 등장했는지를 카운팅하는 방식
    - 이러한 방식으로 문서를 단어 빈도 벡터로 변환하여 기계 학습 모델에 입력
    - 단어의 순서나 문맥은 고려하지 않으며, 단순히 단어의 출현 빈도만을 사용
        
        ![2024-10-19_01-53-06.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/719537e3-c6ce-4507-942c-f1eec3cbd5f2/2024-10-19_01-53-06.jpg)
        

- Bayes’ Rule의 분류 적용
    - **문서 d**가 주어졌을 때 **클래스 c**에 속할 확률
    - $P(c|d) = \frac{P(d|c) \cdot P(c)}{P(d)}$
    

### **(2) Naïve Bayes Classifier 수식**

1. argmax
    - 가능한 모든 클래스 c 중에서 가장 높은 확률을 갖는 클래스를 찾는 과정
    - $\hat{c} = \argmax_{c \in C} P(c|d)$

1. 베이즈 정리 적용
    - 주어진 문서 d에 대해, 클래스 c가 나타날 사후확률 P(c|d)를 최대화하는 클래스 c 선택
    - $\hat{c} = \argmax_{c \in C} \frac{P(d|c)P(c)}{ P(d)}$

1. 분모 생략
    - P(d)는 모든 클래스에 대해 동일하기 때문에, 최종 식에서는 분모 생략 가능 (가장 큰 c를 찾는 과정)
    - $\hat{c} = \argmax_{c \in C} P(d|c) P(c)$

1. 문서 표현 추가
    - 문서는 Bag of Words 모델에서 추출된 단어들의 집합으로 표현 : $𝑑 = ⟨ 𝑓_1,𝑓_2,…,𝑓_𝑛 ⟩$
        - Likelihood : P(f₁, f₂, …, fₙ | c), 주어진 클래스 c에서 문서의 특징들이 발생할 확률
        - Prior : P(c), 문서가 분류될 클래스 c의 발생 확률
    - $\hat{c} = \argmax_{c \in C} P(f₁, f₂, …, fₙ|c) P(c)$
    
- Naive Bayes 분류기의 문제점
    - P(f₁, f₂, …, fₙ|c)를 계산하려면 매우 많은 매개변수가 필요 → O(fₙ · C)의 복잡도를 가짐
    - 모든 특징 조합을 다 계산하려면 매우 많은 훈련 데이터가 필요
    - 훈련 데이터가 적을 경우 정확한 확률을 추정하기 어려움
        
        → 조건부 독립성 가정을 도입
        

### (3) **Multinomial Naïve Bayes Classifier**

- Bag of Words 가정
    - 단어의 위치는 중요하지 않다고 가정
    - 문서 내에서 단어들이 어떤 순서로 나타나는지는 무시하고, 단어의 빈도만을 고려하는 방식

- Conditional Independence (조건부 독립)
    - 각 단어의 확률 P(f₁|c)는 주어진 클래스 c 하에서 독립적으로 나타난다고 가정
    - 특정 클래스 c가 주어졌을 때, 문서에 등장하는 모든 단어들의 발생 확률은 서로 독립적

  ⇒ $P(f₁, f₂, …, fₙ | c) = P(f₁|c) \times P(f₂|c) \times … \times P(fₙ|c)$

- Multinomial Naive Bayes 분류기
    - $c_{NB} = \argmax_{c \in C} P(c) \prod_{f \in F} P(f | c)$

- 단어 위치 고려 시
    - $c_{NB} = \argmax_{c \in C} P(c) \prod_{i \in \text{positions}} P(w_i | c)$
        - $P(w_i | c)$ = 클래스 c가 주어졌을 때 단어 $w_i$가 해당 위치에서 발생할 조건부 확률
        - 모든 단어 위치 i에 대해 곱셈을 수행하여, 주어진 문서가 특정 클래스 c에 속할 확률을 계산
    

### (4) **Laplace Smoothing**

- Maximum Likelihood Estimation (MLE) 학습 방법
    - $\hat{P}(c) = \frac{N_c}{N_{\text{doc}}}$
        - 전체 문서 수 대비 클래스 c에 속하는 문서 수
    - $\hat{P}(w_i | c) = \frac{\text{count}(w_i, c)}{\sum_{w \in V} \text{count}(w, c)}$
        - 모든 단어의 빈도 합 대비 클래스 c에서 단어 $w_i$가 등장한 횟수

- 문제점
    - 훈련 데이터에 특정 단어가 나타나지 않았을 때, 해당 단어의 조건부 확률이 **0**이 되는 상황이 발생 가능
    - Naive Bayes 모델이 문서를 분류할 때, 그 단어가 없다는 이유로 해당 문서가 특정 클래스에 속할 가능성을 완전히 무시하는 결과를 초래
        
        → 해당 문서가 잘못 분류될 가능성이 큼
        

- Laplace Smoothing
    - 모든 단어 빈도에 1을 더해 확률을 조정하는 방법
    - $\hat{P}(w_i | c) = \frac{\text{count}(w_i, c) + 1}{\sum_{w \in V} \text{count}(w, c) + |V|}$ *(V:어휘의 크기)*

- Unknown Words
    - 훈련 데이터에는 없지만 테스트 데이터에 등장하는 단어
        
        → 무시!
        
    - 특정 클래스에서 알 수 없는 단어가 얼마나 많은지 아는 것은 일반적으로 도움이 되지 않기 때문에, 알 수 없는 단어 모델을 따로 구축하지 않음
    - 알 수 없는 단어가 특정 클래스에 속할 가능성은 모델 성능에 큰 영향을 미치지 않음

- Stop Words
    - 매우 자주 등장하지만 의미가 없는 단어 (the, a, …)
    - Stop Words List
        - 가장 자주 등장하는 상위 10개 또는 50개의 단어들을 중지어 목록으로 지정하여 제거할 수 있음
        - 훈련 및 테스트 세트에서 중지어를 완전히 제거하여, 해당 단어들이 모델에 영향을 주지 않도록 처리
    - 실제로는 제거 X
        - 중지어 목록을 사용하지 않는 경우가 많음
        - 중지어를 제거하는 것이 항상 성능 향상에 도움이 되는 것은 아니기 때문

- Underflow 문제
    - 아주 작은 값들을 연속해서 곱할 때, 값이 매우 작아지며 컴퓨터가 이를 정확하게 표현할 수 없는 상태
        
        → 로그 공간(Log Space)으로 해결
        
        - 곱셈을 계속하는 대신, 로그를 취하면 확률을 덧셈으로 계산
        - $P(c_j) \times \prod_{i} P(x_i | c_j)$ → $\log P(c_j) + \sum_{i} \log P(x_i | c_j)$
        - 로그 확률을 더한 값이 가장 높은 클래스가 여전히 가장 높은 확률을 가진 클래스

### (5) 예시

![2024-10-19_03-03-30.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/f4cda141-40de-4898-b2e6-3f3738435606/2024-10-19_03-03-30.jpg)

1. Prior (사전 확률)
    
    $P(c) = \frac{3}{4}$, $P(j) = \frac{1}{4}$
    

1. 조건부확률 (+ Laplace Smoothing)
    - V = 6
    - $P(Chinese|c) = \frac{5 + 1}{8 + 6} = \frac{6}{14} = \frac{3}{7}$
    - $P(Chinese|j) = \frac{1 + 1}{3 + 6} = \frac{2}{9}$
    
    …
    

1. 클래스 선택
    - 테스트 문서가 중국일 경우
        - $P(c|d5) = P(c) \times P(Chinese|c)^3 \times P(Tokyo|c) \times P(Japan|c)$
            
                             $= \frac{3}{4} \times \left( \frac{3}{7} \right)^3 \times \frac{1}{14} \times \frac{1}{14} \approx 0.0003$
            
    - 테스트 문서가 일본일 경우
        - $P(j|d5) = P(j) \times P(Chinese|j)^3 \times P(Tokyo|j) \times P(Japan|j)$
            
                             $= \frac{1}{4} \times \left( \frac{2}{9} \right)^3 \times \frac{2}{9} \times \frac{2}{9} \approx 0.0001$
            
    
    ⇒ 중국
    

## 3. 혼동행렬 (Confusion Matrix)

### (1) 정확도 & 재현율

- 2x2 혼동행렬
    
    ![2024-10-19_04-22-13.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/e2c51085-c211-4add-8486-e9c2e6bbea4a/2024-10-19_04-22-13.jpg)
    
    행 : 모델의 예측 결과 / 열 : 실제 레이블(정답)
    

- 모델이 예측한 결과와 실제 정답의 분포를 시각적으로 표시
    
    → 잘못된 분류를 통해 **모델이 어느 부분에서 오류**를 범하는지 파악할 수 있음
    

- 평가 지표
    
    ![2024-10-19_04-23-24.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/952f7a4b-f1d7-485a-996a-78e910ac8f94/2024-10-19_04-23-24.jpg)
    
    1. 정확도(Precision)
        - 시스템이 양성으로 예측한 것 중에서 실제로 양성인 비율
        - $\text{Precision} = \frac{TP}{TP + FP}$
    2. 재현율(Recall)
        - 실제 양성 중에서 시스템이 양성으로 올바르게 예측한 비율
        - $\text{Recall} = \frac{TP}{TP + FN}$

### (2) F-measure

- Trade-Off
    
    ![2024-10-19_04-25-08.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/e5c3faa1-efaa-45f9-b0e2-13ae050fa741/2024-10-19_04-25-08.jpg)
    
    - 임계값(Threshold)을 설정하여 모델이 얼마나 많은 것을 양성으로 예측할지 결정할 수 있음
        - 임계값을 높이면 정확도가 올라갈 수 있지만, 재현율이 떨어질 수 있음
        - 임계값을 낮추면 재현율이 올라갈 수 있지만, 정확도는 낮아질 수 있음
        
          →  정확도와 재현율 사이에서 적절한 균형을 찾아야 함
        

- F-measure
    - 정확도(Precision)와 재현율(Recall) 간의 균형을 평가하는 지표
    - $F = \frac{(\beta^2 + 1) \cdot P \cdot R}{\beta^2 \cdot P + R}$
        - β(베타) 값에 따라 정확도와 재현율의 가중치를 조정
        - β > 1: 재현율을 더 중요
        - β < 1: 정확도를 더 중요

- F1 measure
    - 일반적으로 사용되는 F-measure
    - β = 1 → 정확도와 재현율을 동일한 중요도로 다룸
    - $F_1 = 2 \cdot \frac{P \cdot R}{P + R}$

## 4. **Macro / Micro averaging**

- 클래스가 여러개인 경우 지표 계산 방법

1. Micro-Averaging
    - 모든 클래스의 결정을 하나의 혼동행렬에 모은 후 전체적으로 계산
    - 데이터가 많은 클래스가 결과에 더 많은 영향을 미침

1. Macro-Averaging
    - 각 클래스별로 개별적으로 성능을 계산한 후, 그 성능들의 평균 계산
    - 각 클래스에 동일한 가중치를 부여하여, 데이터가 적은 클래스도 중요하게 평가

- 예시 (3가지 class)
    
    ![2024-10-19_05-23-22.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/faf6106c-9475-4d1d-9e4f-b0f2375df1a1/2024-10-19_05-23-22.jpg)
